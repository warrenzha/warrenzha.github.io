<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://warrenzha.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://warrenzha.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-06-13T20:36:19+00:00</updated><id>https://warrenzha.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Sparsely Activated BNNs from Deep Gaussian Process</title><link href="https://warrenzha.github.io/blog/2024/dgp/" rel="alternate" type="text/html" title="Sparsely Activated BNNs from Deep Gaussian Process" /><published>2024-06-10T14:14:00+00:00</published><updated>2024-06-10T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2024/dgp</id><content type="html" xml:base="https://warrenzha.github.io/blog/2024/dgp/"><![CDATA[<p><em>Theory and algorithm development:</em> Building on our initial success, we aim to develop a deeper understanding of the nature of the DTMGP models and construct a broader class of DTMGP models with more complex architectures. This will be mainly accomplished by exploring various equivalent expansions of TMGPs and architectures with skip connections or feedback, akin to ResNet or RNN in the deterministic setting. Furthermore, to address the challenge of prior design, we plan to work to understand how the priors (especially, the covariance kernel functions) of the GP units impact the prior of the overall DGP model.</p>

<p><em>Applications to conditional generative tasks:</em> While the primary motivation for studying DGPs in the literature so far has been uncertainty quantification for learning supervised classification/regression, the stochastic nature of these models also makes them natural candidates as generative models. While the general properties of DGPs as generative models are largely unknown, we are encouraged by our preliminary results on applying the DTMGP model to the MNIST dataset_ and the structural similarity between DGPs and the immensely popular Gaussian diffusion models.</p>

<p><em>Software development and validation:</em> We plan to develop software tools that implement the proposed sparsely activated BNNs, which can be used for both regression and generative tasks. The software will be open sourced under the GNU-GPL license, and will be validated using real-world datasets from the state-of-the-art wireless communication and computer vision systems.</p>]]></content><author><name></name></author><category term="Machine-Learning" /><summary type="html"><![CDATA[We developed a sparse expansion of deep Gaussian processes as Bayesian neural networks that are amenable to efficient training and prior design.]]></summary></entry><entry><title type="html">Weakly Private Information Retrieval</title><link href="https://warrenzha.github.io/blog/2024/wpir/" rel="alternate" type="text/html" title="Weakly Private Information Retrieval" /><published>2024-01-29T14:14:00+00:00</published><updated>2024-01-29T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2024/wpir</id><content type="html" xml:base="https://warrenzha.github.io/blog/2024/wpir/"><![CDATA[<p><em>Abstract:</em> We study the problem of weakly private information retrieval (PIR) when there is heterogeneity in servers’ trustfulness under the maximal leakage (Max-L) metric and mutual information (MI) metric. A user wishes to retrieve a desired message from $N$ non-colluding servers efficiently, such that the identity of the desired message is not leaked in a significant manner; however, some servers can be more trustworthy than others. We propose a code construction for this setting and optimize the probability distribution for this construction. For the Max-L metric, it is shown that the optimal probability allocation for the proposed scheme essentially separates the delivery patterns into two parts: a completely private part that has the same download overhead as the capacity-achieving PIR code, and a non-private part that allows complete privacy leakage but has no download overhead by downloading only from the most trustful server. The optimal solution is established through a sophisticated analysis of the underlying convex optimization problem, and a reduction between the homogeneous setting and the heterogeneous setting. For the MI metric, the homogeneous case is studied first for which the code can be optimized with an explicit probability assignment, while a closed-form solution becomes intractable for the heterogeneous case. Numerical results are provided for both cases to corroborate the theoretical analysis.</p>

<p><a href="https://arxiv.org/abs/2402.17940">PDF</a></p>]]></content><author><name></name></author><category term="Coding" /><summary type="html"><![CDATA[We study the problem of weakly private information retrieval (PIR) when there is heterogeneity in servers’ trustfulness under the maximal leakage (Max-L) metric and mutual information (MI) metric.]]></summary></entry><entry><title type="html">AI-driven Dyanmic mmWave Networking</title><link href="https://warrenzha.github.io/blog/2023/mesh-net/" rel="alternate" type="text/html" title="AI-driven Dyanmic mmWave Networking" /><published>2023-04-25T14:14:00+00:00</published><updated>2023-04-25T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2023/mesh-net</id><content type="html" xml:base="https://warrenzha.github.io/blog/2023/mesh-net/"><![CDATA[<p><em>Abstract:</em> Integrated Access and Backhaul (IAB) is an emerging technique to enable cost-effective deployment of dense 
5G networks that utilize emerging millimeter-wavelength (mmWave) spectrum. Existing heuristic-based network 
control/management frameworks are not well-suited for the increasing complexity and uncertainty introduced by mmWave 
IAB. Machine learning (ML) can help automate network control decisions, but its practical deployment faces new 
system-level challenges in 5G IAB, including accurate simulation-based training, resolving conflicting objectives from 
heterogeneous network slices, and efficiently collecting observations for run-time decision-making. In this paper, we 
develop a general framework for effectively deploying reinforcement learning (RL) to control 5G IAB networks. Our 
framework incorporates a data-driven stochastic simulation scheme to bridge the simulation-to-reality gap, a piecewise 
reward shaping mechanism to handle competing conflicting performance objectives, and a simple observation selection 
algorithm to reduce the input size into the RL policy. We validate this framework using real-world network measurements 
from a mmWave IAB testbed, combined with a large scale ray tracing simulation. Experiments on a set of challenging 5G 
IAB network control problems demonstrate the effectiveness of our framework to enable practical RL integration into 5G IAB.</p>

<p><img src="https://github.com/warrenzha/warrenzha.github.io/blob/master/assets/img/posts/mmwavemesh.png" alt="mmwavemesh.png" /></p>
<div class="caption">
    Self-supervised reinforcement learning model and MikroTik testbed for dynamic mmWave mesh network.
</div>

<p><a href="https://warrenzha.github.io/assets/pdf/AIdriven_Dynamic_MillimeterWave_Mesh.pdf">PDF</a></p>]]></content><author><name></name></author><category term="Machine-Learning" /><category term="Communication" /><summary type="html"><![CDATA[We develop a general framework for effectively deploying reinforcement learning (RL) to control 5G mmWave IAB networks.]]></summary></entry><entry><title type="html">Machine Learning and Data Science</title><link href="https://warrenzha.github.io/blog/2022/ml-data-sci/" rel="alternate" type="text/html" title="Machine Learning and Data Science" /><published>2022-04-20T14:14:00+00:00</published><updated>2022-04-20T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2022/ml-data-sci</id><content type="html" xml:base="https://warrenzha.github.io/blog/2022/ml-data-sci/"><![CDATA[<h2 id="gan-based-eeg-signal-generation">GAN-based EEG Signal Generation</h2>

<p><em>Abstract:</em> Processing and analysis of brain signals generally requires a large amount of data. But the acquisition of 
EEG signals is difficult while the sample size of the data set is small, and sometimes categories are unbalanced in the 
data set. Based on the challenge, we proposed the WGAN-GP method, a variant of GAN, to generate useful EEG signals. 
The experiments on single-channel and multi-channel model both show that the performance of WGAN-GP is stable, and the 
generated signals have close shape with the real signals, and have better spectrum performance than traditional methods. 
Our results and analysis show that WGAN-GP can generate accurate and diverse EEG signals, and thus, help extend the data 
set which is difficult to collect physically. We’ve made the code associated with this work available 
at https://github.com/warrenzha/GAN-EEG-generation.</p>

<p><img src="https://github.com/warrenzha/warrenzha.github.io/blob/master/assets/img/posts/ganeeg.png" alt="ganeeg.png" /></p>
<div class="caption">
    Generated EEG signals and convergence rate of WGAN-GP.
</div>

<p><a href="https://warrenzha.github.io/assets/pdf/GAN-EEG-Generation.pdf">PDF</a></p>

<p><a href="https://github.com/warrenzha/GAN-EEG-generation">Link</a></p>

<h2 id="classification-of-online-customer-reviews">Classification of Online Customer Reviews</h2>

<p><em>Abstract:</em> Customer reviews on e-commerce platforms contain valuable information, while sifting through them manually 
tends to dismay people because of the huge amount of data. This study implemented a machine learning-based algorithm to 
classify customer reviews. Our classifier extracts Chinese word segmentation and text frequency for feature extraction 
and scoring, and implements the classification with methods of Naive Bayesian and Support Vector Machines. Experimental 
results on the Taobao product review sentiment datasets show that our model based on two machine learning algorithms, 
though results in different performances, can provide suggestions on the selection of the identification classifier 
using a trade-off strategy and helps obtain fast and accurate classification on reviews of different categories.</p>

<p><a href="https://iopscience.iop.org/article/10.1088/1742-6596/1678/1/012081/pdf">PDF</a></p>]]></content><author><name></name></author><category term="Machine-Learning" /><summary type="html"><![CDATA[We studied the general area of machine learning and data science. A machine learning-based algorithm to is proposed to classify customer reviews. A variant of GAN, WGAN-GP, is designed to extend data set of EEG signals.]]></summary></entry><entry><title type="html">Matrix Optimization and Convex Programming</title><link href="https://warrenzha.github.io/blog/2022/opt-cvx/" rel="alternate" type="text/html" title="Matrix Optimization and Convex Programming" /><published>2022-02-01T14:14:00+00:00</published><updated>2022-02-01T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2022/opt-cvx</id><content type="html" xml:base="https://warrenzha.github.io/blog/2022/opt-cvx/"><![CDATA[<h2 id="blind-deconvolution-using-convex-programming">Blind Deconvolution Using Convex Programming</h2>

<p><em>Abstract:</em> We study the question of recovering two signals w and x from their convolution y = w ∗ x. Generally, the 
solution to this blind deconvolution problem is non-unique and non-convex. But with assumptions on sparsity, subspace 
structure and transformed variable, we can convert the non-convex nuclear norm into a convex problem by ”dual-dual” 
relaxation. In this project, we also implement the convex algorithm proposed in Blind Deconvolution Using Convex 
Programming, and compare its performance with non-blind and non-convex algorithms. Moreover, the evaluation shows that 
the convex algorithm is robust against sparsity violation, but sensitive to low-rank condition. At last, we try to 
extend the algorithm to 2D deconvolution by recovering a blurred image. But the result on 2D deconvolution still need 
improvement.</p>

<p><img src="https://github.com/warrenzha/warrenzha.github.io/blob/master/assets/img/posts/blind.png" alt="blind.png" /></p>
<div class="caption">
    Empirical success rate for the blind deconvolution of 1D and 2D matrices.
</div>

<p><a href="https://github.com/warrenzha/blind-deconvolution">Link</a></p>

<h2 id="ml-based-matrix-optimization-in-massive-mimo">ML-based Matrix Optimization in Massive MIMO</h2>

<p><em>Abstract:</em> In the downlink of massive MIMO, the transmitter uses precoding technology to reduce interference and 
improve spectrum efficiency. A complex-valued gradient neural network (CVGNN) is proposed to solve the 
Moore-Penrose inverse of the complex matrix in massive MIMO precoding algorithms. Theoretical linear convergence and 
numerical results are provided to corroborate the application of CVGNN in wireless communication senarios.</p>

<p><img src="https://github.com/warrenzha/warrenzha.github.io/blob/master/assets/img/posts/cvgnn.png" alt="cvgnn.png" /></p>
<div class="caption">
    Linear convergence of CVGNN when solving complex matrix inverse.
</div>

<p><a href="https://wyzhao030.github.io/assets/pdf/ML_Matrix_Optimization_MIMO.pdf">PDF</a></p>]]></content><author><name></name></author><category term="Optimization" /><category term="Communication" /><summary type="html"><![CDATA[We studied matrix optimization problems using convex programming and machine learning techniques. A complex-valued gradient neural network (CVGNN) is proposed to solve the Moore-Penrose inverse of complex matrices. We also implemented blind deconvolution using convex programming.]]></summary></entry><entry><title type="html">Millimeter Wave Transmission and Beamforming</title><link href="https://warrenzha.github.io/blog/2020/bat/" rel="alternate" type="text/html" title="Millimeter Wave Transmission and Beamforming" /><published>2020-09-28T14:14:00+00:00</published><updated>2020-09-28T14:14:00+00:00</updated><id>https://warrenzha.github.io/blog/2020/bat</id><content type="html" xml:base="https://warrenzha.github.io/blog/2020/bat/"><![CDATA[<h2 id="beam-alignment-and-tracking-for-millimeter-wave-communications-via-bandit-learning">Beam Alignment and Tracking for Millimeter Wave Communications via Bandit Learning</h2>

<p><em>Abstract:</em> Millimeter wave (mmwave) communications have attracted increasing attention thanks to the abundant spectrum 
resource. The short wave-length of mmwave signals facilitates exploiting large antenna arrays to achieve large array 
gains and combat large path-loss. However, the use of large antenna arrays along with narrow beams leads to a large 
overhead in beam training for obtaining channel state information, especially in dynamic environments. To reduce the 
overhead of beam training, in this paper we formulate the problem of beam alignment and tracking (BA/T) as a stochastic 
bandit problem. In particular, to sense the change of the environments, the actions are designed based on the offset of 
successive beam indexes (i.e., beam index difference), which measures the rate of change of the environments. Then, we 
propose two efficient BA/T algorithms based on the stochastic bandit learning. To reveal useful insights, the performance 
of effective achievable rate is further analyzed for the proposed BA/T algorithms. The analytical results show that the 
algorithms can sense the change of the environments and adjust beam training strategies intelligently. In addition, they 
do not require any priori knowledge of dynamic channel modeling, and thus are applicable to a variety of complicated 
scenarios. Simulation results demonstrate the effectiveness and superiority of the proposed algorithms.</p>

<p><img src="https://github.com/warrenzha/warrenzha.github.io/blob/master/assets/img/posts/bat.png" alt="bat.png" /></p>
<div class="caption">
    An illustration of a point-to-point mmwave communication system and beam training in each time-slot.
</div>]]></content><author><name></name></author><category term="Communication" /><summary type="html"><![CDATA[We formulated the problem of mmWave beam alignment and tracking (BA/T) as a stochastic bandit problem. The analytical results show that the algorithms can sense the change of the environments and adjust beam training strategies intelligently.]]></summary></entry></feed>